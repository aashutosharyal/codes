{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Prakrut Kansara (phk5e@virginia.edu)\n",
    "\n",
    "Description: This file takes in MODIS ET hdf files and extracts subdataset corresponding to ET. It then mosaics all the different tiles into a single tile. It projects the input sinusoidal projection to WGS84 projection for output. It saves this output in GeoTIFF format. Finally, it converts 8-day ET data to monthly data (For the conversion, 8-day value is divided by 8 and then multiplied by number of days in corresponding month). The output files will be stored with the name: 'MODIS_ET_YYYYMM.tif'\n",
    "\n",
    "Date created: 10th May, 2020\n",
    "\n",
    "Date last updated: 14th May, 2020\n",
    "\n",
    "Version: 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gdal, osr, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2019-11-01 00:00:00\n2019-12-27 00:00:00\n"
    }
   ],
   "source": [
    "# Use this to find out the starting date and ending date \n",
    "print(pd.to_datetime('2019305', format= '%Y%j'))\n",
    "print(pd.to_datetime('2019361', format= '%Y%j'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Inputs - Change all the inputs required for this code in the code block below. There is no need to change anything else in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-11-01'\n",
    "end_date = '2019-12-27'\n",
    "\n",
    "src_dir = 'C:/Users/prakr/Desktop/Sarah_et/data' # Give the full path to the folder/directory where data is stored\n",
    "dst_dir = 'C:/Users/prakr/Desktop/Sarah_et/output' # Give the full path to the folder/directory where you want the output to be stored\n",
    "\n",
    "subdataset_id = [0] # index of layers to be extracted. For MODIS ET data: ET_500m, LE_500m, PET_500m, PLE_500m, ET_QC_500m\n",
    "                    # https://lpdaac.usgs.gov/products/mod16a2v006/\n",
    "                    # The number of layers can be acquired by GetSubDatasets()\n",
    "band_n = 1\n",
    "\n",
    "scale_factor = 0.1 #https://lpdaac.usgs.gov/products/mod16a2v006/\n",
    "\n",
    "# Set the boundary coordinates of the map to subset\n",
    "lat_roi_max = 16\n",
    "lat_roi_min = 2\n",
    "lon_roi_max = 50\n",
    "lon_roi_min = 32\n",
    "\n",
    "nodata = 32760\n",
    "\n",
    "date_start = 11\n",
    "date_end = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Step 1: Create a function to extract subdatasets from HDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf_subdataset_extraction(hdf_files, dst_dir, subdataset_id, band_n):\n",
    "\n",
    "    # Open the dataset\n",
    "    global band_ds\n",
    "    hdf_ds = gdal.Open(hdf_files, gdal.GA_ReadOnly)\n",
    "#hdf_ds = gdal.Open(t, gdal.GA_ReadOnly)\n",
    "    # Loop read data of specified bands from subdataset_id\n",
    "    size_1dim = gdal.Open(hdf_ds.GetSubDatasets()[0][0], gdal.GA_ReadOnly).ReadAsArray().astype(np.int16).shape\n",
    "    band_array = np.empty([size_1dim[0], size_1dim[1], len(subdataset_id)], dtype=int)\n",
    "    for idn in range(len(subdataset_id)):\n",
    "        band_ds = gdal.Open(hdf_ds.GetSubDatasets()[subdataset_id[idn]][0], gdal.GA_ReadOnly)\n",
    "        # Read into numpy array\n",
    "        band_array[:, :, idn] = band_ds.ReadAsArray().astype(np.int16)\n",
    "\n",
    "    # Build output path\n",
    "    band_path = os.path.join(dst_dir, os.path.basename(os.path.splitext(hdf_files)[0]) + \"-ctd\" + \".tif\")\n",
    "    # Write raster\n",
    "    out_ds = gdal.GetDriverByName('GTiff').Create(band_path, band_ds.RasterXSize, band_ds.RasterYSize, band_n, #Number of bands\n",
    "                                  gdal.GDT_Int16, ['COMPRESS=LZW', 'TILED=YES'])\n",
    "    out_ds.SetGeoTransform(band_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(band_ds.GetProjection())\n",
    "\n",
    "    # Loop write each band to Geotiff file\n",
    "    for idb in range(len(subdataset_id)):\n",
    "        out_ds.GetRasterBand(idb+1).WriteArray(band_array[:, :, idb])\n",
    "        out_ds.GetRasterBand(idb+1).SetNoDataValue(0)\n",
    "    out_ds = None  #close dataset to write to disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Step 2: Generate the list of dates for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "end_date = datetime.datetime.strptime(end_date, '%Y-%m-%d').date()\n",
    "delta_date = end_date - start_date\n",
    "\n",
    "date_seq = []\n",
    "for i in range(delta_date.days + 1):\n",
    "    date_str = start_date + datetime.timedelta(days=i)\n",
    "    date_seq.append(str(date_str.timetuple().tm_year) + str(date_str.timetuple().tm_yday).zfill(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Step 3: Extract the subdataset to separate HDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data\\MOD16A2GF.A2019305.h21v07.006.2020025232447.hdf\ndata\\MOD16A2GF.A2019305.h21v08.006.2020026004413.hdf\ndata\\MOD16A2GF.A2019305.h22v07.006.2020026014017.hdf\ndata\\MOD16A2GF.A2019305.h22v08.006.2020026024452.hdf\ndata\\MOD16A2GF.A2019313.h21v07.006.2020026013750.hdf\ndata\\MOD16A2GF.A2019313.h21v08.006.2020026031247.hdf\ndata\\MOD16A2GF.A2019313.h22v07.006.2020026033906.hdf\ndata\\MOD16A2GF.A2019313.h22v08.006.2020026043249.hdf\ndata\\MOD16A2GF.A2019321.h21v07.006.2020026035044.hdf\ndata\\MOD16A2GF.A2019321.h21v08.006.2020026050447.hdf\ndata\\MOD16A2GF.A2019321.h22v07.006.2020026052859.hdf\ndata\\MOD16A2GF.A2019321.h22v08.006.2020026061454.hdf\ndata\\MOD16A2GF.A2019329.h21v07.006.2020026053121.hdf\ndata\\MOD16A2GF.A2019329.h21v08.006.2020026064013.hdf\ndata\\MOD16A2GF.A2019329.h22v07.006.2020026072904.hdf\ndata\\MOD16A2GF.A2019329.h22v08.006.2020026074835.hdf\ndata\\MOD16A2GF.A2019337.h21v07.006.2020026073212.hdf\ndata\\MOD16A2GF.A2019337.h21v08.006.2020026081522.hdf\ndata\\MOD16A2GF.A2019337.h22v07.006.2020026093511.hdf\ndata\\MOD16A2GF.A2019337.h22v08.006.2020026095129.hdf\ndata\\MOD16A2GF.A2019345.h21v07.006.2020026093724.hdf\ndata\\MOD16A2GF.A2019345.h21v08.006.2020026095808.hdf\ndata\\MOD16A2GF.A2019345.h22v07.006.2020026112516.hdf\ndata\\MOD16A2GF.A2019345.h22v08.006.2020026115004.hdf\ndata\\MOD16A2GF.A2019353.h21v07.006.2020026113532.hdf\ndata\\MOD16A2GF.A2019353.h21v08.006.2020026114708.hdf\ndata\\MOD16A2GF.A2019353.h22v07.006.2020026130239.hdf\ndata\\MOD16A2GF.A2019353.h22v08.006.2020026133005.hdf\ndata\\MOD16A2GF.A2019361.h21v07.006.2020026125234.hdf\ndata\\MOD16A2GF.A2019361.h21v08.006.2020026131207.hdf\ndata\\MOD16A2GF.A2019361.h22v07.006.2020026135759.hdf\ndata\\MOD16A2GF.A2019361.h22v08.006.2020026142225.hdf\n"
    }
   ],
   "source": [
    "\n",
    "hdf_files = sorted(glob.glob('data/*.hdf'))##\n",
    "\n",
    "for idt in range(len(hdf_files)):\n",
    "    hdf_subdataset_extraction(hdf_files[idt], dst_dir, subdataset_id, band_n)\n",
    "    print(hdf_files[idt]) # Print the file being processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Step 4: Create virtual files to mosaic all the tiles into a single tile of raster and save it as GeoTIFF. Print the file names corresponding to mosaic output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MOD16A2GF_A2019305\nMOD16A2GF_A2019313\nMOD16A2GF_A2019321\nMOD16A2GF_A2019329\nMOD16A2GF_A2019337\nMOD16A2GF_A2019345\nMOD16A2GF_A2019353\nMOD16A2GF_A2019361\n"
    }
   ],
   "source": [
    "os.chdir(dst_dir)\n",
    "tif_files = sorted(glob.glob('*.tif'))##\n",
    "tif_files_group = []\n",
    "for idt in range(len(date_seq)):\n",
    "    tif_files_group_1day = [tif_files.index(i) for i in tif_files if 'A' + date_seq[idt] in i]\n",
    "    tif_files_group.append(tif_files_group_1day)\n",
    "\n",
    "vrt_options = gdal.BuildVRTOptions(resampleAlg='near', addAlpha=None, bandList=None)\n",
    "for idt in range(len(tif_files_group)):\n",
    "    if len(tif_files_group[idt]) != 0:\n",
    "        tif_files_toBuild = [tif_files[i] for i in tif_files_group[idt]]\n",
    "        vrt_files_name = '_'.join(tif_files[tif_files_group[idt][0]].split('.')[0:2])\n",
    "        gdal.BuildVRT('mosaic_sinu_' + vrt_files_name + '.vrt', tif_files_toBuild, options=vrt_options)\n",
    "        exec('mosaic_sinu_' + vrt_files_name + '= None')\n",
    "\n",
    "dst_srs = osr.SpatialReference()\n",
    "dst_srs.ImportFromEPSG(4326) # WGS 84 projection\n",
    "dst_wkt = dst_srs.ExportToWkt()\n",
    "error_threshold = 0.1  # error threshold\n",
    "resampling = gdal.GRA_NearestNeighbour\n",
    "\n",
    "vrt_files = sorted(glob.glob('*.vrt'))\n",
    "for idt in range(len(vrt_files)):\n",
    "    # Open file\n",
    "    src_ds = gdal.Open(vrt_files[idt])\n",
    "    mos_file_name = '_'.join(os.path.splitext(vrt_files[idt])[0].split('_')[2:4])\n",
    "    # Call AutoCreateWarpedVRT() to fetch default values for target raster dimensions and geotransform\n",
    "    tmp_ds = gdal.AutoCreateWarpedVRT(src_ds, None, dst_wkt, resampling, error_threshold)\n",
    "    # Crop to CONUS extent and create the final warped raster\n",
    "    dst_ds = gdal.Translate(mos_file_name + '.tif', tmp_ds,\n",
    "                            projWin=[lon_roi_min, lat_roi_max, lon_roi_max, lat_roi_min])\n",
    "    dst_ds = None\n",
    "\n",
    "    print(mos_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Step 5: Seperate the individual files corresponding to each month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 1]\n",
    "feb_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 2]\n",
    "mar_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 3]\n",
    "apr_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 4]\n",
    "may_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 5]\n",
    "jun_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 6]\n",
    "jul_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 7]\n",
    "aug_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 8]\n",
    "sep_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 9]\n",
    "oct_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 10]\n",
    "nov_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 11]\n",
    "dec_files = [name for name in os.listdir('.') if name.endswith('.tif') and 'ctd' not in name and pd.to_datetime(name[date_start:date_end],format='%Y%j').month == 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Step 6: Create function to convert 8-day to monthly value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_empty_month():\n",
    "    if len(jan_files) != 0:\n",
    "        return jan_files\n",
    "    if len(feb_files) != 0:\n",
    "        return feb_files\n",
    "    if len(mar_files) != 0:\n",
    "        return mar_files\n",
    "    if len(apr_files) != 0:\n",
    "        return apr_files\n",
    "    if len(may_files) != 0:\n",
    "        return may_files\n",
    "    if len(jun_files) != 0:\n",
    "        return jun_files\n",
    "    if len(jul_files) != 0:\n",
    "        return jul_files\n",
    "    if len(aug_files) != 0:\n",
    "        return aug_files\n",
    "    if len(sep_files) != 0:\n",
    "        return sep_files\n",
    "    if len(oct_files) != 0:\n",
    "        return oct_files\n",
    "    if len(nov_files) != 0:\n",
    "        return nov_files\n",
    "    if len(dec_files) != 0:\n",
    "        return dec_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = rasterio.open(non_empty_month()[0]).profile\n",
    "raster_shape = rasterio.open(non_empty_month()[0]).shape\n",
    "\n",
    "def monthly(file_list):\n",
    "    data = np.empty((raster_shape[0],raster_shape[1],1))\n",
    "    if len(file_list) > 0:\n",
    "        for i in range(len(file_list)):\n",
    "            file_open = rasterio.open(file_list[i])\n",
    "            file = file_open.read(1)\n",
    "            file = np.reshape(file,(file.shape[0], file.shape[1], 1))\n",
    "            data = np.append(data,file, axis=2)\n",
    "            data_new = np.delete(data, 0, axis=2)\n",
    "        data_new[data_new > nodata] = np.nan\n",
    "        data_mean = np.nanmean(data_new, axis=2)\n",
    "        data_final = (data_mean/8)*scale_factor*pd.to_datetime(file_list[0][date_start:date_end],format='%Y%j').days_in_month\n",
    "        with rasterio.open('MODIS_ET_'+ str(pd.to_datetime(file_list[0][date_start:date_end],format='%Y%j').year) + str(pd.to_datetime(file_list[0][date_start:date_end],format='%Y%j').month).zfill(2) + '.tif', 'w', **profile) as dst:\n",
    "                dst.write(data_final.astype(rasterio.int16), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________________________________________________\n",
    "Step 7: Use the function to create monthly files for the whole time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly(jan_files)\n",
    "monthly(feb_files)\n",
    "monthly(mar_files)\n",
    "monthly(apr_files)\n",
    "monthly(may_files)\n",
    "monthly(jun_files)\n",
    "monthly(jul_files)\n",
    "monthly(aug_files)\n",
    "monthly(sep_files)\n",
    "monthly(oct_files)\n",
    "monthly(nov_files)\n",
    "monthly(dec_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36764bitc8cb9c822c094b60876a00c191e0ae70",
   "display_name": "Python 3.6.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}